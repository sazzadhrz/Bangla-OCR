{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import pprint\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    OCR DATASET CLASS\n",
    "    Dataset Used = BanglaWriting\n",
    "    Dataset Manual = https://arxiv.org/pdf/2011.07499.pdf\n",
    "    Dataset Download Link - https://data.mendeley.com/datasets/r43wkvdk4w/1\n",
    "'''\n",
    "\n",
    "class  OCRDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, targets):\n",
    "        self.img_dir = img_dir\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_dir)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image = Image.open(self.img_dir[item])\n",
    "        image = image.resize((128, 64), resample=Image.BILINEAR)\n",
    "\n",
    "        targets = self.targets[item]\n",
    "\n",
    "        image = np.array(image)\n",
    "        image = np.stack((image,)*1, axis=-1)\n",
    "\n",
    "        # Reshape to tensor format supported by Pytorch (C, H, W)\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "\n",
    "        return {\n",
    "            \"images\": torch.tensor(image, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.long),\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model\n",
    "\n",
    "class OCRModel(nn.Module):\n",
    "    def __init__(self, num_chars):\n",
    "        super(OCRModel, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(1, 128, kernel_size=(3, 6), padding=(1, 1))\n",
    "        self.pool_1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.conv_2 = nn.Conv2d(128, 64, kernel_size=(3, 6), padding=(1, 1))\n",
    "        self.pool_2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.linear_1 = nn.Linear(1024, 64) # 1024 = 64*16\n",
    "        self.drop_1 = nn.Dropout(0.2)\n",
    "        self.gru = nn.GRU(64, 32, bidirectional=True, num_layers=2, dropout=0.25, batch_first=True)\n",
    "        self.output = nn.Linear(64, num_chars + 1)\n",
    "\n",
    "    def forward(self, images, targets=None):\n",
    "        bs, c, h, w = images.size()\n",
    "        # print(\"bs, c, h, w = \", bs, c, h, w)\n",
    "        x = F.relu(self.conv_1(images))\n",
    "        # print(x.size())\n",
    "        x = self.pool_1(x)\n",
    "        # print(x.size())\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        # print(x.size())\n",
    "        x = self.pool_2(x) # [8, 64, 16, 29] (bs, c, h, w)\n",
    "        # print(x.size())\n",
    "        \n",
    "        x = x.permute(0, 3, 1, 2) # bs, w, c, h\n",
    "        # print(x.size())           # 8, 29, 64, 16 \n",
    "        x = x.view(bs, x.size(1), -1)\n",
    "        # print(x.size())\n",
    "        x = F.relu(self.linear_1(x))\n",
    "        x = self.drop_1(x)\n",
    "        # print(x.size())\n",
    "        \n",
    "        x, _ = self.gru(x)\n",
    "        # print(x.size())\n",
    "        x = self.output(x)\n",
    "        # print(x.size())\n",
    "        \n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        if targets is not None:\n",
    "            log_probs = F.log_softmax(x, 2).to(torch.float64)\n",
    "            input_lengths = torch.full(\n",
    "                size=(bs,), fill_value=log_probs.size(0), dtype=torch.int32\n",
    "            )\n",
    "            # print(input_lengths)\n",
    "            target_lengths = torch.full(\n",
    "                size=(bs,), fill_value=targets.size(1), dtype=torch.int32\n",
    "            )\n",
    "            # print(target_lengths)\n",
    "            loss = nn.CTCLoss(blank=0)(\n",
    "                log_probs, targets, input_lengths, target_lengths\n",
    "            )\n",
    "#             print(loss)\n",
    "            return x, loss\n",
    "\n",
    "        return x, None\n",
    "\n",
    "\n",
    "#\n",
    "if __name__ == \"__main__\":\n",
    "    cm = OCRModel(115)\n",
    "    img = torch.rand((32, 1, 64, 128))\n",
    "    x, _ = cm(img, torch.rand((32, 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(x):\n",
    "    if len(x) < 2:\n",
    "        return x\n",
    "    fin = \"\"\n",
    "    for j in x:\n",
    "        if fin == \"\":\n",
    "            fin = j\n",
    "        else:\n",
    "            if j == fin[-1]:\n",
    "                continue\n",
    "            else:\n",
    "                fin = fin + j\n",
    "    return fin\n",
    "\n",
    "\n",
    "def decode_predictions(preds, encoder):\n",
    "    preds = preds.permute(1, 0, 2)\n",
    "    preds = torch.softmax(preds, 2)\n",
    "    preds = torch.argmax(preds, 2)\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    word_preds = []\n",
    "    for j in range(preds.shape[0]):\n",
    "        temp = []\n",
    "        for k in preds[j, :]:\n",
    "            k = k - 1\n",
    "            if k == -1:\n",
    "                temp.append(\"Â°\")\n",
    "            else:\n",
    "                p = encoder.inverse_transform([k])[0]\n",
    "                temp.append(p)\n",
    "        tp = \"\".join(temp)\n",
    "        word_preds.append(remove_duplicates(tp))\n",
    "    return word_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train and test functions\n",
    "\n",
    "def train_fn(model, data_loader, optimizer):\n",
    "    model.train()\n",
    "    fin_loss = 0\n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    \n",
    "\n",
    "    for data in tk0:\n",
    "        for key, value in data.items():\n",
    "            data[key] = value.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        optimizer.zero_grad()\n",
    "        _, loss = model(**data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        fin_loss += loss.item()\n",
    "    return fin_loss / len(data_loader)\n",
    "\n",
    "\n",
    "def eval_fn(model, data_loader):\n",
    "    model.eval()\n",
    "    fin_loss = 0\n",
    "    fin_preds = []\n",
    "    with torch.no_grad():\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "        for data in tk0:\n",
    "            for key, value in data.items():\n",
    "                data[key] = value.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            batch_preds, loss = model(**data)\n",
    "            fin_loss += loss.item()\n",
    "            fin_preds.append(batch_preds)\n",
    "        return fin_preds, fin_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './img/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    print('train function is running')\n",
    "    image_files = glob.glob(os.path.join(filepath, '*jpg'))\n",
    "    targets_orig = [x.split(\"\\\\\")[1].split(\" \")[0] for x in image_files]\n",
    "#     print(targets_orig)\n",
    "    targets = [[c for c in x] for x in targets_orig]\n",
    "    targets_flat = [c for clist in targets for c in clist]\n",
    "    \n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    lbl_enc.fit(targets_flat)\n",
    "    targets_enc = [lbl_enc.transform(x) for x in targets]\n",
    "    targets_enc = np.array(targets_enc) + 1\n",
    "#     print(targets_enc)\n",
    "    \n",
    "    #############################################################################################\n",
    "#     num = 3635\n",
    "#     print(targets[num])  # target length (# 12650 = 9)\n",
    "#     print(\"Target label length =\", len(targets_enc[num]))\n",
    "    #############################################################################################\n",
    "    \n",
    "    \n",
    "    # add padding to labels to make the target length equal for every target/label\n",
    "    maxlen = len(max(targets, key=len)) # to get the length of the largest label\n",
    "    # print(maxlen)\n",
    "    # print(max(targets, key=len))\n",
    "    \n",
    "    # iterating over every target and adding 0 at the last\n",
    "    for item in range(len(targets_enc)):\n",
    "        difference = maxlen - len(targets_enc[item]) \n",
    "        for i in range(difference):\n",
    "            targets_enc[item] = np.append(targets_enc[item], 0)\n",
    "#             np.pad(targets_enc[item], (0, difference), 'constant')\n",
    "\n",
    "    \n",
    "    print(\"Total unique classes/characters:\", len(lbl_enc.classes_))\n",
    "#     print(lbl_enc.classes_[114])\n",
    "#     print(np.unique(targets_flat))\n",
    "    \n",
    "    # divide into train test \n",
    "    (\n",
    "        train_imgs,\n",
    "        test_imgs,\n",
    "        train_targets,\n",
    "        test_targets,\n",
    "        train_orig_targets,\n",
    "        test_orig_targets,\n",
    "    ) = model_selection.train_test_split (\n",
    "        image_files, targets_enc, targets_orig, test_size = 0.2, random_state = 42\n",
    "    )\n",
    "    \n",
    "    # loading images and their corresponding labels to train and test dataset\n",
    "    train_dataset = OCRDataset(img_dir = train_imgs, targets = train_targets)\n",
    "    test_dataset = OCRDataset(img_dir = test_imgs, targets = test_targets)\n",
    "    \n",
    "    # defining the data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    \n",
    "    # model goes here\n",
    "    model = OCRModel(len(lbl_enc.classes_))\n",
    "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, factor=0.8, patience=5, verbose=True\n",
    "    )\n",
    "\n",
    "    # define number of epoch and start training\n",
    "    num_epoch = 10\n",
    "    for epoch in range(num_epoch):\n",
    "        train_loss = train_fn(model, train_loader, optimizer)\n",
    "        valid_preds, test_loss = eval_fn(model, test_loader)\n",
    "        valid_word_preds = []\n",
    "        \n",
    "        for vp in valid_preds:\n",
    "            current_preds = decode_predictions(vp, lbl_enc)\n",
    "            valid_word_preds.extend(current_preds)\n",
    "        combined = list(zip(test_orig_targets, valid_word_preds))\n",
    "        print(combined[:10])\n",
    "        test_dup_rem = [remove_duplicates(c) for c in test_orig_targets]\n",
    "        accuracy = metrics.accuracy_score(test_dup_rem, valid_word_preds)\n",
    "        pprint(list(zip(test_orig_targets, valid_word_preds))[6:11])\n",
    "        print(\n",
    "            f\"Epoch={epoch}, Train Loss={train_loss}, Test Loss={test_loss} Accuracy={accuracy}\"\n",
    "        )\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Visualize train data and its shape\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "npimg = train_dataset[200]['images'].numpy()\n",
    "print(npimg.shape) # print current shape (torch style)\n",
    "\n",
    "# change the orientation of the image to display\n",
    "npimg = np.transpose(npimg, (1, 2, 0)).astype(np.float32)\n",
    "print(npimg.shape)\n",
    "\n",
    "plt.imshow(npimg)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
